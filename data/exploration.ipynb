{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('USvideos.csv').drop_duplicates('video_id', 'first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify constants for vocabulary operations.\n",
    "DELIMITERS = re.compile(r' |\\\\n|\\|')\n",
    "PUNCTUATION = re.compile(r'[.:;,?!\\\"|#()-]|^\\'|\\'$')\n",
    "STOP_PATTERN = re.compile(r'http|www')\n",
    "STOP_WORDS = set(['the', 'a', 'and', 'or', 'of'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map categories indices to labels.\n",
    "categories = {\n",
    "    1: 'Film & Animation',\n",
    "    2: 'Autos & Vehicles',\n",
    "    10: 'Music',\n",
    "    15: 'Pets & Animals',\n",
    "    17: 'Sports',\n",
    "    18: 'Short Movies',\n",
    "    19: 'Travel & Events',\n",
    "    20: 'Gaming',\n",
    "    21: 'Videoblogging',\n",
    "    22: 'People & Blogs',\n",
    "    23: 'Comedy',\n",
    "    24: 'Entertainment',\n",
    "    25: 'News & Politics',\n",
    "    26: 'Howto & Style',\n",
    "    27: 'Education',\n",
    "    28: 'Science & Technology',\n",
    "    29: 'Nonprofits & Activism',\n",
    "    30: 'Movies',\n",
    "    31: 'Anime/Animation',\n",
    "    32: 'Action/Adventure',\n",
    "    33: 'Classics',\n",
    "    34: 'Comedy',\n",
    "    35: 'Documentary',\n",
    "    36: 'Drama',\n",
    "    37: 'Family',\n",
    "    38: 'Foreign',\n",
    "    39: 'Horror',\n",
    "    40: 'Sci-Fi/Fantasy',\n",
    "    41: 'Thriller',\n",
    "    42: 'Shorts',\n",
    "    43: 'Shows',\n",
    "    44: 'Trailers'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect vocabulary by category from tags.\n",
    "vocabularies = {}\n",
    "n = 10000\n",
    "# Consider each category in the data.\n",
    "for category in data['category_id'].unique():\n",
    "    vocab = {}\n",
    "    # Consider tags for each video in this category.\n",
    "    for tags in data.loc[data['category_id'] == category, 'tags']:\n",
    "        words = re.split(DELIMITERS, tags)\n",
    "        # Consider each word among these tags.\n",
    "        for word in words:\n",
    "            word = re.sub(PUNCTUATION, '', word).lower()\n",
    "            # Skip this word if it matches the stop pattern.\n",
    "            if re.search(STOP_PATTERN, word):\n",
    "                continue\n",
    "            # Update the vocabulary with this word.\n",
    "            if word not in vocab:\n",
    "                vocab[word] = 0\n",
    "            vocab[word] += 1\n",
    "    # Keep only the n most frequent words.\n",
    "    vocab = {word for word, _ in Counter(vocab).most_common(n)}\n",
    "    # Add this set to the mapping of categories to vocabulary.\n",
    "    vocabularies[category] = vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Most similar categories:\n",
      "Comedy AND Entertainment: 2563\n",
      "People & Blogs AND Entertainment: 2294\n",
      "Entertainment AND Howto & Style: 2278\n",
      "Music AND Entertainment: 2077\n",
      "Film & Animation AND Entertainment: 1880\n",
      "Entertainment AND News & Politics: 1751\n",
      "People & Blogs AND Howto & Style: 1563\n",
      "Sports AND Entertainment: 1548\n",
      "People & Blogs AND Comedy: 1519\n",
      "Entertainment AND Science & Technology: 1511\n",
      "\n",
      "Most dissimilar categories:\n",
      "Nonprofits & Activism AND Shows: 8\n",
      "Travel & Events AND Nonprofits & Activism: 24\n",
      "Pets & Animals AND Shows: 25\n",
      "Travel & Events AND Shows: 25\n",
      "Autos & Vehicles AND Nonprofits & Activism: 27\n",
      "Autos & Vehicles AND Shows: 36\n",
      "Gaming AND Shows: 36\n",
      "Gaming AND Nonprofits & Activism: 38\n",
      "Pets & Animals AND Nonprofits & Activism: 43\n",
      "Education AND Shows: 58\n"
     ]
    }
   ],
   "source": [
    "# Compare the intersections of vocabulary between categories.\n",
    "intersections = []\n",
    "keys = vocabularies.keys()\n",
    "for i in keys:\n",
    "    for j in keys:\n",
    "        if j <= i:\n",
    "            continue\n",
    "        n = len(vocabularies[i] & vocabularies[j])\n",
    "        intersections.append((i, j, n))\n",
    "# Give the most similar and most different category pairings.\n",
    "intersections.sort(key=lambda x: x[2])\n",
    "print('\\nMost similar categories:')\n",
    "for k in range(1, 11):\n",
    "    i, j, n = intersections[-k]\n",
    "    print('%s AND %s: %d' % (categories[i], categories[j], n))\n",
    "print('\\nMost dissimilar categories:')\n",
    "for k in range(10):\n",
    "    i, j, n = intersections[k]\n",
    "    print('%s AND %s: %d' % (categories[i], categories[j], n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "People & Blogs:\n",
      "\tVideos:   498 (0.078)\n",
      "\t Words:  4135\n",
      "\n",
      "Entertainment:\n",
      "\tVideos:  1619 (0.255)\n",
      "\t Words:  9552\n",
      "\n",
      "Comedy:\n",
      "\tVideos:   547 (0.086)\n",
      "\t Words:  4450\n",
      "\n",
      "Science & Technology:\n",
      "\tVideos:   380 (0.060)\n",
      "\t Words:  3507\n",
      "\n",
      "Film & Animation:\n",
      "\tVideos:   318 (0.050)\n",
      "\t Words:  3073\n",
      "\n",
      "News & Politics:\n",
      "\tVideos:   505 (0.080)\n",
      "\t Words:  3541\n",
      "\n",
      "Sports:\n",
      "\tVideos:   451 (0.071)\n",
      "\t Words:  3373\n",
      "\n",
      "Music:\n",
      "\tVideos:   799 (0.126)\n",
      "\t Words:  4306\n",
      "\n",
      "Pets & Animals:\n",
      "\tVideos:   138 (0.022)\n",
      "\t Words:  1460\n",
      "\n",
      "Education:\n",
      "\tVideos:   250 (0.039)\n",
      "\t Words:  3299\n",
      "\n",
      "Howto & Style:\n",
      "\tVideos:   595 (0.094)\n",
      "\t Words:  4496\n",
      "\n",
      "Autos & Vehicles:\n",
      "\tVideos:    70 (0.011)\n",
      "\t Words:   911\n",
      "\n",
      "Travel & Events:\n",
      "\tVideos:    60 (0.009)\n",
      "\t Words:   793\n",
      "\n",
      "Gaming:\n",
      "\tVideos:   103 (0.016)\n",
      "\t Words:  1124\n",
      "\n",
      "Nonprofits & Activism:\n",
      "\tVideos:    14 (0.002)\n",
      "\t Words:   215\n",
      "\n",
      "Shows:\n",
      "\tVideos:     4 (0.001)\n",
      "\t Words:   179\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Show the size of the data and vocabulary in each category.\n",
    "for i, vocab in vocabularies.items():\n",
    "    n = data[data['category_id'] == i].shape[0]\n",
    "    print('%s:' % categories[i])\n",
    "    print('\\tVideos: %5d (%.3f)' % (n, n / data.shape[0]))\n",
    "    print('\\t Words: %5d\\n' % len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
