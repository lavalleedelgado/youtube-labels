{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from youtube_transcript_api import YouTubeTranscriptApi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data and get a random permutation of video ids.\n",
    "data = pd.read_csv('USvideos.csv').drop_duplicates('video_id', 'first')\n",
    "videos_ids = np.random.permutation(data['video_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribute video ids into ten batches.\n",
    "video_id_batches = []\n",
    "n_batches = 10\n",
    "n_ids = data.shape[0] // n_batches + 1\n",
    "for i in range(n_batches):\n",
    "    idx = i * n_ids\n",
    "    video_ids = list(videos_ids[idx:idx+n_ids])\n",
    "    video_id_batches.append(video_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get captions for each batch of video ids.\n",
    "for i in range(1, len(video_id_batches)):\n",
    "    video_ids, transcripts, unavailable = [], [], []\n",
    "    # Try to get transcripts for each video in this batch.\n",
    "    for video_id in video_id_batches[i]:\n",
    "        try:\n",
    "            # Download and save the original captions for this video.\n",
    "            captions = YouTubeTranscriptApi.get_transcript(video_id)\n",
    "            with open(f'{video_id}.json', mode='w') as f:\n",
    "                f.write(json.dumps(captions))\n",
    "            # Concatenate the captions into a complete transcript.\n",
    "            transcript = ' '.join(caption['text'] for caption in captions).replace('\\n', ' ')\n",
    "            # Append the video id and transcript.\n",
    "            video_ids.append(video_id)\n",
    "            transcripts.append(transcript)\n",
    "        except:\n",
    "            # Append the video id among those unavailable.\n",
    "            unavailable.append(video_id)\n",
    "        # Wait a few seconds before making the next request.\n",
    "        time.sleep(4)\n",
    "    # Write the available transcripts from this batch to file.\n",
    "    with open('transcripts.txt', mode='a') as f:\n",
    "        for data in zip(video_ids, transcripts):\n",
    "            f.write('%s\\t%s\\n' % data)\n",
    "    # Write the unavailable video ids in this batch to faile.\n",
    "    with open('unavailable.txt', mode='a') as f:\n",
    "        for video_id in unavailable:\n",
    "            f.write('%s\\n' % video_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
