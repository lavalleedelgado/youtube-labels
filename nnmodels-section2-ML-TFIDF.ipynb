{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "j2cnpmGXiNaD"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import copy\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torchtext import data\n",
    "import torch.utils.data as d\n",
    "import tokenization_dim_reduction as tdr\n",
    "import ngrams as ng\n",
    "\n",
    "data_dir = r'D:\\Researching Data\\Youtube data\\USvideos.csv'\n",
    "torch.backends.cudnn.deterministic = True\n",
    "TEXT = data.Field(tokenize = 'spacy')\n",
    "LABEL = data.LabelField(dtype = torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, dtext, dlabel = tdr.select_col(data_dir, tdr.cols_t4)\n",
    "new_TEXT = tdr.combine_text(dtext, 1, [0,2])\n",
    "#new_label = tdr.multi_to_binary(dlabel, 25) # politics\n",
    "new_label = tdr.multi_to_binary(dlabel, 24) # entertainments\n",
    "new_arr = np.concatenate((new_TEXT.reshape([len(new_TEXT),1]), new_label), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt_tfidf = tdr.tfidf_tokenization(new_TEXT)\n",
    "#torch_tfidf = torch.from_numpy(txt_tfidf.toarray())\n",
    "new_TEXT = txt_tfidf.toarray()\n",
    "new_label = tdr.multi_to_binary(dlabel, 24)\n",
    "new_arr = np.concatenate((new_TEXT, new_label), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the current shape of the reduced data is  (6351, 5000)\n"
     ]
    }
   ],
   "source": [
    "# select 5000 words with highest average tfidf\n",
    "top5k_indices = np.argsort(np.apply_along_axis(np.mean, 0, new_TEXT))[-5000:]\n",
    "new_TEXT = new_TEXT[:, top5k_indices]\n",
    "new_arr = np.concatenate((new_TEXT, new_label), axis=1)\n",
    "print(\"the current shape of the reduced data is \", new_TEXT.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dimensional_reduction(df, k, get_test_df=False, test_df=\"\"):\n",
    "    '''\n",
    "    The function is designed to make dimensional reduction with SVD method\n",
    "    Inputs:\n",
    "        df: original matrix\n",
    "        k: the number of singular values taken\n",
    "        y: label vector\n",
    "        allm: if True, return the components of economic SVD\n",
    "    Returns: approximated df with k singular values\n",
    "    '''\n",
    "    U_k = np.linalg.svd(df)[0][:, :k]\n",
    "    sigma_k = np.linalg.svd(df)[1][:k]\n",
    "    Vt_k = np.linalg.svd(df)[2][:k, :]\n",
    "\n",
    "    reduced_df = (Vt_k[:k, :].dot(df.T)).T\n",
    "\n",
    "    if get_test_df:\n",
    "        return reduced_df, (Vt_k[:k, :].dot(test_df.T)).T\n",
    "    \n",
    "    return reduced_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ml75oPv6iNaJ"
   },
   "outputs": [],
   "source": [
    "# split train, validation, test\n",
    "def split_train_test(dt_size, train_valid_test_r):\n",
    "    '''\n",
    "    The function randomly selects the indices for\n",
    "    training, validation, and testing sets\n",
    "    Inputs:\n",
    "        dt_size: number of rows\n",
    "        train_valid_test_r: tuple of ratios\n",
    "    Return: indices for each subset\n",
    "    '''\n",
    "    train_size = int(dt_size * train_valid_test_r[0] // 1)\n",
    "    valid_size = int(dt_size * train_valid_test_r[1] // 1)\n",
    "    test_size = int(dt_size - train_size - valid_size)\n",
    "    print(\"the size of train, valid and test data are\", train_size, valid_size, test_size)\n",
    "    \n",
    "    full_indices = np.arange(0, dt_size, 1)\n",
    "    train_indices = np.random.permutation(full_indices)[:train_size]\n",
    "    \n",
    "    sub_indices = set(full_indices) - set(train_indices)\n",
    "    valid_indices = np.random.permutation(list(sub_indices))[:valid_size]\n",
    "    \n",
    "    sub_indicest = set(sub_indices) - set(valid_indices)\n",
    "    test_indices = np.array(list(sub_indicest))\n",
    "    \n",
    "    return train_indices, valid_indices, test_indices "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_reduced_data(path, arr, y, k=500, train_valid_test_r=(0.4, 0.4, 0.2)):\n",
    "    '''\n",
    "    The function split the data to train, validation and test\n",
    "    sets with randomly selected indices and save them to seperated\n",
    "    csv files\n",
    "    Inputs:\n",
    "        path: directory of the saved files\n",
    "        arr: the whole dataset\n",
    "        train_valid_test_r: tuple of ratios\n",
    "    '''\n",
    "    train_indices, valid_indices, test_indices = split_train_test(arr.shape[0], train_valid_test_r)\n",
    "    \n",
    "    red_train, red_valid = dimensional_reduction(arr[train_indices], k, True, arr[valid_indices])\n",
    "    red_train, red_test = dimensional_reduction(arr[train_indices], k, True, arr[test_indices])\n",
    "    \n",
    "    pd.DataFrame(red_train).to_csv(path + \"\\\\train.csv\", header=None, index=None)\n",
    "    pd.DataFrame(red_valid).to_csv(path + \"\\\\valid.csv\", header=None, index=None)\n",
    "    pd.DataFrame(red_test).to_csv(path + \"\\\\test.csv\", header=None, index=None)\n",
    "    \n",
    "    return (red_train, y[train_indices], red_valid, y[valid_indices], \n",
    "            red_test, y[test_indices])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the size of train, valid and test data are 2540 2540 1271\n"
     ]
    }
   ],
   "source": [
    "path = r'D:\\Researching Data\\Youtube data\\tfidf'\n",
    "X_train, y_train, X_valid, y_valid, X_test, y_test =\\\n",
    "split_reduced_data(path, new_TEXT, new_label, 500, train_valid_test_r=(0.4, 0.4, 0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "\n",
    "parameter_dict = {\"random_forest\":{'n_estimators': [1, 10,100], 'max_depth': [5,50],\n",
    "                              'max_features': ['sqrt','log2'],'min_samples_split': [2,10]},\n",
    "             \"logistics\": {'penalty': [\"l1\",'l2'], 'C': [0.001,0.1,1]}}\n",
    "\n",
    "clfs = {'random_forest': RandomForestClassifier(n_jobs=2),\n",
    "        'logistics': LogisticRegression(C=1e5, solver='liblinear')}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifier_developer(method, clfs, parameter_dict):\n",
    "    '''\n",
    "    This function is used to generate possible combination of hyperparameters of\n",
    "    given classifiers\n",
    "    Inputs:\n",
    "        method: specific classifiers\n",
    "        clfs: dictionary of classifiers\n",
    "        parameter_dict: parameters dictionary for the classifiers\n",
    "    Returns: list of all possible combination of parameters\n",
    "    '''\n",
    "    parameters = parameter_dict[method]\n",
    "    para_list = ParameterGrid(parameters)\n",
    "\n",
    "    return para_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_acc(y_pred, y_real):\n",
    "    '''\n",
    "    The helper function to evaluate the accuracy\n",
    "    of true label and predicted probability\n",
    "    '''\n",
    "    pdy1 = np.zeros(len(y_pred))\n",
    "    pdy1[y_pred >= 0.5] = 1\n",
    "    pdy2 = np.zeros(len(y_pred))\n",
    "    pdy2[pdy1 == y_real[:, 0]] = 1\n",
    "    \n",
    "    return sum(pdy2) / len(pdy2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ml_evaluate(clfs, parameter_dict, X_train, y_train, X_valid, y_valid,\n",
    "                X_test, y_test):\n",
    "    '''\n",
    "    The function evaluated the performance of each machine learning\n",
    "    model type and with the hyper-parameters defined in the parameter-\n",
    "    dict. The best accuracy of each model type is presented in the\n",
    "    output.\n",
    "    Inputs:\n",
    "        clfs: dictionary of classifiers\n",
    "        parameter_dict: dictionary of parameters for each classifier\n",
    "        X_train, y_train, X_valid, y_valid, X_test, y_test\n",
    "    Returns: dictionary with model type, parameters and best accuracy\n",
    "    '''\n",
    "    outputs_dict = {}\n",
    "    for method, _ in clfs.items():\n",
    "        if method in parameter_dict:\n",
    "            print(\"operation of {} method begins\".format(method))\n",
    "            para_list = classifier_developer(method, clfs, parameter_dict)\n",
    "            best_acc = 0\n",
    "            for para in para_list:\n",
    "                clf = clfs[method].set_params(**para)\n",
    "                model_name = method + \" with parameters : \" + str(clf.get_params())\n",
    "                model = clf.fit(X_train, y_train[:, 0])\n",
    "                \n",
    "                y_v_predp = model.predict_proba(X_valid)[:, 1]\n",
    "                y_t_predp = model.predict_proba(X_test)[:, 1]\n",
    "                acc_v = eval_acc(y_v_predp, y_valid)\n",
    "                acc_t = eval_acc(y_t_predp, y_test)\n",
    "\n",
    "                if acc_v > best_acc:\n",
    "                    best_acc = acc_t\n",
    "                    best_model = model_name\n",
    "            \n",
    "            outputs_dict[method] = (best_model, best_acc)\n",
    "            print(\"the best accuracy for method: \", method,  \" is \", best_acc)\n",
    "\n",
    "    return outputs_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "operation of random_forest method begins\n",
      "the best accuracy for method:  random_forest  is  0.8387096774193549\n",
      "operation of logistics method begins\n",
      "the best accuracy for method:  logistics  is  0.8394964594807238\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'random_forest': (\"random_forest with parameters : {'bootstrap': True, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': 50, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 1, 'min_samples_split': 10, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_jobs': 2, 'oob_score': False, 'random_state': None, 'verbose': 0, 'warm_start': False}\",\n",
       "  0.8387096774193549),\n",
       " 'logistics': (\"logistics with parameters : {'C': 1, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 100, 'multi_class': 'auto', 'n_jobs': None, 'penalty': 'l1', 'random_state': None, 'solver': 'liblinear', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}\",\n",
       "  0.8394964594807238)}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ml_evaluate(clfs, parameter_dict, X_train, y_train, X_valid, y_valid, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "KnhR3qF_iNYc"
   ],
   "name": "mlpp20-hw2-collab.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
