{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from collections import Counter\n",
    "from functionized_code.data_pipeline import get_labels_and_corpus, get_vocab\n",
    "from run_pipeline import LABEL_TO_IDX, get_data, get_column_indices\n",
    "\n",
    "IDX_TO_LABEL = {i: l for l, i in LABEL_TO_IDX.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set parameters for vocabulary.\n",
    "MAX_VOCAB = 25000\n",
    "NGRAMS = 1\n",
    "\n",
    "# Identify the names of the columns for the labels and corpus.\n",
    "col_labels = 'category_id'\n",
    "col_corpus = ['title', 'tags', 'description', 'caption']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vocabulary without captions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the video data without captions.\n",
    "data_wo_captions = get_data(captions=False)\n",
    "# Get the labels and corpus.\n",
    "idx_labels, idx_corpus = get_column_indices(data_wo_captions, col_labels, col_corpus[:3])\n",
    "labels_wo_captions, corpus_wo_captions = get_labels_and_corpus(\n",
    "    data_wo_captions, idx_labels, idx_corpus, silent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Intersection of vocabularies without captions\n"
    }
   ],
   "source": [
    "print('Intersection of vocabularies without captions')\n",
    "# Get vocabulary for News & Politics.\n",
    "i = LABEL_TO_IDX['News & Politics']\n",
    "target_corpus = corpus_wo_captions[labels_wo_captions == i]\n",
    "target_vocab, _ = get_vocab(target_corpus, MAX_VOCAB, NGRAMS)\n",
    "target_vocab = set(target_vocab)\n",
    "target_len = len(target_vocab)\n",
    "# Compare to intersections of vocabulary with other categories.\n",
    "for j in np.unique(labels_wo_captions):\n",
    "    # Skip self.\n",
    "    if j == i:\n",
    "        continue\n",
    "    # Get vocabulary for this other category.\n",
    "    other_corpus = corpus_wo_captions[labels_wo_captions == j]\n",
    "    other_vocab, _ = get_vocab(other_corpus, MAX_VOCAB, NGRAMS)\n",
    "    other_vocab = set(other_vocab)\n",
    "    other_len = len(other_vocab)\n",
    "    # Count the number of words at the intersection.\n",
    "    n = len(target_vocab & other_vocab)\n",
    "    # Report.\n",
    "    values = (IDX_TO_LABEL[i], target_len, IDX_TO_LABEL[j], other_len, n)\n",
    "    print('%s (%d) AND %s (%d): %d' % values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vocabulary with captions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the video data with captions.\n",
    "data_w_captions = get_data(captions=True)\n",
    "# Get the labels and corpus.\n",
    "idx_labels2, idx_corpus2 = get_column_indices(data_wo_captions, col_labels, col_corpus)\n",
    "labels_w_captions, labels_w_captions = get_labels_and_corpus(\n",
    "    data_w_captions, idx_labels2, idx_corpus2, silent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Intersection of vocabularies without captions')\n",
    "# Get vocabulary for News & Politics.\n",
    "i = LABEL_TO_IDX['News & Politics']\n",
    "target_corpus = corpus_w_captions[labels_w_captions == i]\n",
    "target_vocab, _ = get_vocab(target_corpus, MAX_VOCAB, NGRAMS)\n",
    "target_vocab = set(target_vocab)\n",
    "target_len = len(target_vocab)\n",
    "# Compare to intersections of vocabulary with other categories.\n",
    "for j in np.unique(labels_w_captions):\n",
    "    # Skip self.\n",
    "    if j == i:\n",
    "        continue\n",
    "    # Get vocabulary for this other category.\n",
    "    other_corpus = corpus_w_captions[labels_w_captions == j]\n",
    "    other_vocab, _ = get_vocab(other_corpus, MAX_VOCAB, NGRAMS)\n",
    "    other_vocab = set(other_vocab)\n",
    "    other_len = len(other_vocab)\n",
    "    # Count the number of words at the intersection.\n",
    "    n = len(target_vocab & other_vocab)\n",
    "    # Report.\n",
    "    values = (IDX_TO_LABEL[i], target_len, IDX_TO_LABEL[j], other_len, n)\n",
    "    print('%s (%d) AND %s (%d): %d' % values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}